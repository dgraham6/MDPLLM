{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679db73a-bc0e-4164-b89d-9da89879b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from PyPDF2 import PdfReader\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1eb9b7-8bf9-40bd-8e14-c43fc16e9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_biorxiv_pdf_urls():\n",
    "    base_url = \"https://www.biorxiv.org\"\n",
    "    pdf_urls = []\n",
    "\n",
    "    for page_number in range(1, 170): \n",
    "        page_url = f\"{base_url}/content/early/recent?page={page_number}\"\n",
    "        response = requests.get(page_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            article_links = soup.find_all(\"a\", class_=\"highwire-cite-linked-title\")\n",
    "            \n",
    "            for article_link in article_links:\n",
    "                article_href = article_link.get(\"href\")\n",
    "                if article_href:\n",
    "                    article_url = base_url + article_href\n",
    "                    article_response = requests.get(article_url)\n",
    "                    \n",
    "                    if article_response.status_code == 200:\n",
    "                        article_soup = BeautifulSoup(article_response.content, \"html.parser\")\n",
    "                        pdf_link = article_soup.find(\"a\", class_=\"article-dl-pdf-link\")\n",
    "                        \n",
    "                        if pdf_link:\n",
    "                            pdf_href = pdf_link.get(\"href\")\n",
    "                            if pdf_href and pdf_href.endswith(\".pdf\"):\n",
    "                                full_pdf_url = base_url + pdf_href\n",
    "                                pdf_urls.append(full_pdf_url)\n",
    "    \n",
    "    return pdf_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8236112-90be-4d8c-82a0-5746943cca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\"\n",
    "groq_client = Groq(api_key=api_key)\n",
    "\n",
    "def load_pdf_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(\"temp.pdf\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        reader = PdfReader(\"temp.pdf\")\n",
    "        text = \"\".join([page.extract_text() for page in reader.pages])\n",
    "        return text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to download PDF from {url}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def scrape_website(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        content = \"\\n\".join([para.get_text() for para in paragraphs])\n",
    "        return content\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to scrape website {url}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    pdf_urls = [\n",
    "        \"https://www.biorxiv.org/content/10.1101/2020.07.28.224253v1.full.pdf\",\n",
    "        \"https://www.cartercenter.org/resources/pdfs/health/ephti/library/lecture_notes/health_extension_trainees/generalpathology.pdf\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "    website_urls = [\n",
    "        \"https://en.wikipedia.org/wiki/Pathology\",\n",
    "        \"https://www.mcgill.ca/pathology/about/definition#:~:text=Pathology%20is%20a%20branch%20of,the%20whole%20body%20(autopsy).\"\n",
    "    ]\n",
    "\n",
    "    pdf_urls.extend(scrape_biorxiv_pdf_urls())\n",
    "    documents_with_metadata = []\n",
    "\n",
    "    for url in pdf_urls:\n",
    "        data = load_pdf_from_url(url)\n",
    "        if data:\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "            splits = text_splitter.split_text(data)\n",
    "            for split in splits:\n",
    "                documents_with_metadata.append(Document(page_content=split, metadata={\"source\": url}))\n",
    "\n",
    "\n",
    "    for url in website_urls:\n",
    "        data = scrape_website(url)\n",
    "        if data:\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "            splits = text_splitter.split_text(data)\n",
    "            for split in splits:\n",
    "                documents_with_metadata.append(Document(page_content=split, metadata={\"source\": url}))\n",
    "\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"chromadb\"):\n",
    "        os.makedirs(\"chromadb\")\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents_with_metadata, \n",
    "        embedding=embedding_model, \n",
    "        persist_directory=\"chromadb\"\n",
    "    )\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "vectorstore = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d68c5-e17f-438f-b614-c00343e0b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(question):\n",
    "\n",
    "    template = \"\"\"\n",
    "    Use the following pieces of context to answer the question at the end.\n",
    "    If you don't know the answer, just say that you don't know; don't try to make up an answer.\n",
    "    Keep the answer as concise as possible, preferably in three sentences.\n",
    "    Quote the url the info came from.\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    context_docs = retriever.get_relevant_documents(question)\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in context_docs])\n",
    "\n",
    "\n",
    "    prompt = template.format(context=context_text, question=question)\n",
    "\n",
    "\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\"\n",
    "    )\n",
    "\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "question = \"Finish this sentance, The study of pathology, including the detailed examination of the body,\"\n",
    "answer = query_rag(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3980488-c6e2-4dad-acd5-a89f4ad9cc85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
