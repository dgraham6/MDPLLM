{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fd62bed-5d7d-4f61-800a-2da228df4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import groq\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f24b801-972a-49fa-a845-dee315dcdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llama(query_string):\n",
    "    client = groq.Groq(\n",
    "        api_key= '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'\n",
    "    )\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_string\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "        #temperature=0 # Try uncommenting this and running the call to query_llama below many times. What do you notice? Recomment it out afterwards.\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a4faf0f-ac38-4c16-94bd-b78ab03b28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    string1 = string.lower()\n",
    "    return re.findall(r'\\b\\w+\\b', string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b030e14b-79f2-4c0e-b3e9-5ef388976512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(path):\n",
    "    return [f for f in os.listdir(path) if f.endswith('.txt')]\n",
    "\n",
    "def count_tokens(tokens):\n",
    "    Numtoken = {}\n",
    "    for token in tokens:\n",
    "        if token in Numtoken:\n",
    "            Numtoken[token] += 1\n",
    "        else:\n",
    "            Numtoken[token] = 1\n",
    "    return Numtoken\n",
    "\n",
    "def files_to_bow(path):\n",
    "    bow_data = {}\n",
    "    files = helper(path)\n",
    "    all_tokens = set()\n",
    "    \n",
    "    for file in files:\n",
    "        with open(os.path.join(path, file), 'r') as f:\n",
    "            tokens = tokenize(f.read())\n",
    "            token_counts = count_tokens(tokens)\n",
    "            bow_data[file] = token_counts\n",
    "            all_tokens.update(tokens)\n",
    "    sorted_tokens = sorted(all_tokens)\n",
    "    df = pd.DataFrame(index=sorted(bow_data.keys()), columns=sorted_tokens).fillna(0)\n",
    "    for file_name, counts in bow_data.items():\n",
    "        for token, count in counts.items():\n",
    "            df.at[file_name, token] = count\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1846f0d9-1fca-4524-943b-781012cd71ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idfs(bow):\n",
    "    d = bow.shape[0]\n",
    "    a = bow.map(lambda x: 1 if x != 0 else x)\n",
    "    b = a.sum(axis=0)\n",
    "    return np.log(d / b) \n",
    "\n",
    "def bow_to_tfidf(bow):\n",
    "    tf = bow.div(bow.sum(axis=1), axis=0)\n",
    "    idf = compute_idfs(bow)\n",
    "    tfidf = tf.multiply(idf, axis=1)\n",
    "    return tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "216b7aed-d3fa-41c8-918f-0139a5a7ead5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_query_to_tfidf\u001b[39m(query_string, bow\u001b[38;5;241m=\u001b[39m\u001b[43mbow\u001b[49m):\n\u001b[1;32m      2\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokenize(query_string)\n\u001b[1;32m      3\u001b[0m     query_bow \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(count_tokens(tokens))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bow' is not defined"
     ]
    }
   ],
   "source": [
    "def new_query_to_tfidf(query_string, bow=bow):\n",
    "    tokens = tokenize(query_string)\n",
    "    query_bow = pd.Series(count_tokens(tokens))\n",
    "    missing_words = [word for word in query_bow.index if word not in bow.columns]\n",
    "    \n",
    "    if missing_words:\n",
    "        extended_columns = bow.columns.tolist() + missing_words\n",
    "    else:\n",
    "        extended_columns = bow.columns.tolist()\n",
    "    query_bow = query_bow.reindex(extended_columns, fill_value=0)\n",
    "\n",
    "    query_tf = query_bow / query_bow.sum()\n",
    "    \n",
    "    idfs = compute_idfs(bow)\n",
    "\n",
    "    for word in missing_words:\n",
    "        idfs[word] = 0\n",
    "    \n",
    "    idfs = idfs.reindex(extended_columns, fill_value=0)\n",
    "\n",
    "    query_tfidf = query_tf * idfs\n",
    "    \n",
    "    return query_tfidf.reindex(bow.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de1b64b0-dfe9-4cc4-a5bf-5b9f9da98e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dot_product \u001b[38;5;241m/\u001b[39m (b \u001b[38;5;241m*\u001b[39m a)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtop_n_similar_documents\u001b[39m(query_string, n, bow\u001b[38;5;241m=\u001b[39m\u001b[43mbow\u001b[49m):\n\u001b[1;32m     11\u001b[0m     query_tfidf \u001b[38;5;241m=\u001b[39m new_query_to_tfidf(query_string, bow)\n\u001b[1;32m     13\u001b[0m     doc_tfidf_matrix \u001b[38;5;241m=\u001b[39m bow_to_tfidf(bow) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'bow' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    b = np.linalg.norm(vec1)\n",
    "    a = np.linalg.norm(vec2)\n",
    "    \n",
    "    if a == 0 or b == 0:\n",
    "        return 0\n",
    "    return dot_product / (b * a)\n",
    "\n",
    "def top_n_similar_documents(query_string, n, bow=bow):\n",
    "    query_tfidf = new_query_to_tfidf(query_string, bow)\n",
    "\n",
    "    doc_tfidf_matrix = bow_to_tfidf(bow) \n",
    "    \n",
    "    similarities = {}\n",
    "    for doc_name in doc_tfidf_matrix.index:\n",
    "        doc_vector = doc_tfidf_matrix.loc[doc_name]\n",
    "        similarity = cosine_similarity(query_tfidf, doc_vector)\n",
    "        similarities[doc_name] = similarity\n",
    "\n",
    "    sorted_docs = sorted(similarities, key=similarities.get, reverse=True)\n",
    "\n",
    "    return sorted_docs[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e65445ad-4c37-4c68-866a-0b0c2e28225b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask_gpteecs\u001b[39m(query_string, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, bow\u001b[38;5;241m=\u001b[39m\u001b[43mbow\u001b[49m):\n\u001b[1;32m      2\u001b[0m     top_docs \u001b[38;5;241m=\u001b[39m top_n_similar_documents(query_string, n, bow)\n\u001b[1;32m      3\u001b[0m     syllabi_contents \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bow' is not defined"
     ]
    }
   ],
   "source": [
    "def ask_gpteecs(query_string, n=3, bow=bow):\n",
    "    top_docs = top_n_similar_documents(query_string, n, bow)\n",
    "    syllabi_contents = []\n",
    "    for doc in top_docs:\n",
    "        try:\n",
    "            with open(f'data/syllabi/{doc}', 'r') as file:\n",
    "                syllabus_text = file.read()\n",
    "                syllabi_contents.append(f\"Here is the syllabus for course {doc}:\\n{syllabus_text}\")\n",
    "        except FileNotFoundError:\n",
    "            syllabi_contents.append(f\"Here is {doc}: [Syllabus not found]\")\n",
    "\n",
    "    combined_query = f\"\"\"\n",
    "    Hi! I'm looking to answer this query about EECS courses at the University of Michigan:\n",
    "    \n",
    "\n",
    "    {query_string}\n",
    "\n",
    "    Here are some relevant courses from the syllabi:\n",
    "    Include the Proffesors who teach the classes\n",
    "    And conclude which the course the fits the query best\n",
    "    \"\"\"\n",
    "    \n",
    "    random.shuffle(syllabi_contents)\n",
    "    combined_query += \"\\n\\n\".join(syllabi_contents)\n",
    "    combined_query += f\"\\n\\nQuery Variation Seed: {random.randint(1000, 9999)}\"\n",
    "    try:\n",
    "        response = query_llama(combined_query)\n",
    "        return response\n",
    "    except groq.RateLimitError:\n",
    "        return \"Rate limit reached. Please try again later.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
